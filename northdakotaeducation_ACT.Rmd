---
title: "North Dakota ACT Scores"
author: "Xanna Burg"
date: "5/28/2020"
output: html_document
---

## Indicator 1: Average ACT composite scores
## Indicator 2: High school graduates meeting ACT college benchmark scores, by subject area

**Created by:** Xanna Burg
**Date:** May 2020
**Updated by:**

**Data Source:** North Dakota Department of Public Instruction
**Purpose:** Import DPI data, clean data, and output dataset to upload to KIDS COUNT Data Center.

**Data format:** Final output csv to upload is in long format with the following variables: Location (character: name of location), TimeFrame (text: years), Category (character), Data (numeric: number, percentage), DataFormat (character: "number" or "percent"), LocationId (numeric: assigned for KIDS COUNT system)


**To use this code for a new year:**
* Update the year in the second code chunk for variable 'year'
* Manually enter the statewide data (from PDF)
* Check each dataset visually and through the report logs prior to commiting to the database.


```{r,message=FALSE}
#install required packages the first time you use this code
#install.packages('tidyverse')
#install.packages('tidycensus')
#install.packages('censusapi')
#install.packages('stringr')

#load required packages
library(tidyverse)
library(tidycensus)
library(censusapi)
library(stringr)
library(readxl)
```


```{r}
#CHANGE THE OBJECTS 'statename' and 'year' TO MATCH THE STATE AND YEAR
#state should match exactly as is in FIPS code in order for code to correctly run
statename <- "North Dakota"
year <- "2024"


#run this code to create an object needed for the database (DO NOT EDIT)
database_state <- 'northdakota'

#import the location ids matching the correct state (DO NOT EDIT)
locationids <- read.csv("./Input/ND KC Location IDs.csv")
locationids$Location <- as.character(locationids$Location) #assign as character instead of factor for merging

#import the region match file matching the correct state (DO NOT EDIT)
regionids <- read.csv("./Input/ND KC Region List.csv") 
regionids$county <- as.character(regionids$county)
regionids$region <- as.character(regionids$region)

#import the lookup table for county name
countyids <- read.csv("./Documentation/Indicator Documentation/North Dakota Data Requests/ND County Codes.csv")
```

## ############################ ##
## AVERAGE ACT COMPOSITE SCORES ##
## ############################ ##
```{r}
act_composite <- read_excel('/Users/xannaburg/Documents/DO NOT DELETE/ND Education/ND Kids Count 2025 Request/ACT_new_approach.xlsx')

############
#COUNTY DATA
act_composite_county <- act_composite %>%
  #remove NA, which means that a composite score was not calculated
  subset(!is.na(ACTScaleScores_Composite)) %>%
  #clean up the county names and codes
  mutate(County=as.numeric(paste(County))) %>%
  full_join(countyids,by=c('County'='ndcounty_number')) %>%
  select(-c(County)) %>%
  rename(location=ndcounty_name) %>%
  
  #calculate average by county
  group_by(location) %>%
  summarise(count=n(),
    data=mean(ACTScaleScores_Composite)) %>%
  
  #suppress if fewer than 25 took the ACT
  mutate(data=if_else(count<25,NA,data)) %>%
  select(-c(count)) %>%
  
  mutate(locationtype='County') %>%
  mutate(state='North Dakota') %>%
  mutate(timeframe=year) %>%
  mutate(dataformat='Number') %>%
  mutate(varname='averageactcompositescore')

###########
#STATE DATA
#pull the state composite score from the Class Profile pdf
state_data <- 19.6

act_composite_state <- as.data.frame(state_data) %>%
  rename(data=state_data) %>%
  mutate(location='North Dakota') %>%
  mutate(locationtype='State') %>%
  mutate(state='North Dakota') %>%
  mutate(timeframe=year) %>%
  mutate(dataformat='Number') %>%
  mutate(varname='averageactcompositescore')
  
#########################
#COMBINE STATE AND COUNTY
act_composite_cleaned <- act_composite_county %>%
  bind_rows(act_composite_state) %>%
  left_join(locationids,by=c('location'='Location')) %>%
  rename(locationid=LocationId)

####################
####################
#DATA QUALITY CHECKS
### Before moving forward, check the output log for errors in addition to checking specifically for these quality checks

# 1. Print name of location that has a mismatched location ID
if (sum(is.na(act_composite_cleaned$locationid))>=1) {
  print(act_composite_cleaned$location[is.na(act_composite_cleaned$locationid)])
} else if (sum(is.na(act_composite_cleaned$locationid))==0) {
  'all locations match'
}


# 2. Visually inspect output data
View(act_composite_cleaned)
```

## STEP 2: COMMIT TO DATABASE 
```{r}
#CHECK DATASET NAMED act_composite_cleaned TO VERIFY DATA ISN'T MISSING AND APPEARS CORRECT
#this code adds kids count data to MBPC postgres database
#run postgres code (separate file) first
dbWriteTable(con,database_state,act_composite_cleaned,append=TRUE,row.names=FALSE)
```

## STEP 3: OUTPUT DATASET FOR UPLOADING TO KC DATA CENTER
```{r}
#########################
##OUTPUT DATA CENTER FILE

datacenter_sql <- paste0("SELECT locationid, location, timeframe, dataformat, data FROM ", database_state," WHERE timeframe='",year,"' AND varname='averageactcompositescore';")

upload_data <- dbGetQuery(con,datacenter_sql) %>%
  rename(LocationId=locationid,
         Location=location,
         TimeFrame=timeframe,
         DataFormat=dataformat,
         Data=data)

#SAVE OUTPUT DATASET TO UPLOAD TO DATA CENTER
write.csv(upload_data,file=paste0("./Output/education/",database_state,"_",year,"_averageactcompositescore.csv"),row.names=FALSE)

```




